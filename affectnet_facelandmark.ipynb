{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "# Dataset path\n",
    "data_path = \"/CSCI2952X/datasets/affectnet_3750subset\"\n",
    "\n",
    "# Load the dataset using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_path, 'train'), transform=None)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(data_path, 'test'), transform=None)\n",
    "\n",
    "# Print dataset distribution\n",
    "print(\"Training Dataset Distribution:\")\n",
    "print(Counter(train_dataset.targets))\n",
    "\n",
    "print(\"Test Dataset Distribution:\")\n",
    "print(Counter(test_dataset.targets))\n",
    "\n",
    "# Initialize Mediapipe face mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "def extract_mediapipe_landmarks(image_np):\n",
    "    \"\"\"\n",
    "    Extract facial landmarks using Mediapipe from a NumPy image.\n",
    "    \"\"\"\n",
    "    # Ensure image is in RGB format\n",
    "    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect face landmarks\n",
    "    results = face_mesh.process(image_rgb)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = []\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for lm in face_landmarks.landmark:\n",
    "                x = int(lm.x * image_np.shape[1])\n",
    "                y = int(lm.y * image_np.shape[0])\n",
    "                landmarks.append((x, y))\n",
    "        return landmarks\n",
    "    return None  # No face detected\n",
    "\n",
    "# Process images in the dataset\n",
    "for idx, (image_path, label) in enumerate(train_dataset.samples):  # ImageFolder stores samples as (path, label)\n",
    "    print(f\"Processing image {idx + 1}...\")\n",
    "\n",
    "    # Load the image using OpenCV\n",
    "    image_np = cv2.imread(image_path)  # OpenCV loads in BGR format\n",
    "\n",
    "    # Extract Mediapipe landmarks for the image\n",
    "    landmarks = extract_mediapipe_landmarks(image_np)\n",
    "    if landmarks:\n",
    "        print(f\"Image {idx} (Label {label}) Landmarks: {landmarks[:5]}...\")  # Display first 5 landmarks\n",
    "\n",
    "        # Plot the image and landmarks\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for display\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot landmarks on the image\n",
    "        for x, y in landmarks:\n",
    "            plt.scatter(x, y, c='red', s=5)  # Scatter plot for landmarks\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Image {idx} (Label {label}): No face detected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
